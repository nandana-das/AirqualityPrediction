{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Air Quality Data Exploration\n",
        "\n",
        "This notebook provides comprehensive exploratory data analysis (EDA) for the air quality prediction project.\n",
        "\n",
        "## Objectives\n",
        "1. Load and examine the raw air quality dataset\n",
        "2. Analyze data quality and completeness\n",
        "3. Explore city-wise patterns and distributions\n",
        "4. Identify key insights for feature engineering\n",
        "5. Generate initial visualizations\n",
        "\n",
        "## Dataset Information\n",
        "- **Source**: Kaggle \"Air Quality Data in India (2015‚Äì2020)\"\n",
        "- **Target Cities**: Delhi, Bangalore, Kolkata, Hyderabad, Chennai, Visakhapatnam\n",
        "- **Features**: PM2.5, PM10, NO, NO2, NOx, NH3, CO, SO2, O3, Benzene, Toluene, AQI, Date, City\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas is already installed\n",
            "numpy is already installed\n",
            "matplotlib is already installed\n",
            "seaborn is already installed\n",
            "plotly is already installed\n",
            "Installing scikit-learn...\n",
            "lightgbm is already installed\n",
            "optuna is already installed\n",
            "Installing imbalanced-learn...\n",
            "tqdm is already installed\n",
            "joblib is already installed\n",
            "Libraries imported successfully!\n",
            "Current working directory: d:\\Nandana\\MTECH\\PREDICTIVE ANALYSIS\\AirqualityPrediction\\air_quality_prediction\\notebooks\n"
          ]
        }
      ],
      "source": [
        "# Install required packages if not already installed\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install package using pip if not already installed.\"\"\"\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"{package} is already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Install required packages\n",
        "required_packages = [\n",
        "    \"pandas\",\n",
        "    \"numpy\", \n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"plotly\",\n",
        "    \"scikit-learn\",\n",
        "    \"lightgbm\",\n",
        "    \"optuna\",\n",
        "    \"imbalanced-learn\",\n",
        "    \"tqdm\",\n",
        "    \"joblib\"\n",
        "]\n",
        "\n",
        "for package in required_packages:\n",
        "    install_package(package)\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files found in data directory: ['city_day.csv', 'city_hour.csv', 'stations.csv', 'station_day.csv', 'station_hour.csv']\n",
            "‚úÖ Loaded city_day.csv successfully!\n",
            "Dataset shape: (29531, 16)\n",
            "Columns: ['City', 'Date', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket']\n",
            "\n",
            "Target cities for analysis: ['Delhi', 'Bangalore', 'Kolkata', 'Hyderabad', 'Chennai', 'Visakhapatnam']\n"
          ]
        }
      ],
      "source": [
        "# Define data path and load the dataset\n",
        "data_path = \"../data/raw/\"\n",
        "\n",
        "# Check if data directory exists and list files\n",
        "if os.path.exists(data_path):\n",
        "    files = os.listdir(data_path)\n",
        "    print(f\"Files found in data directory: {files}\")\n",
        "    \n",
        "    # Load the main dataset - city_day.csv (daily city-level data)\n",
        "    try:\n",
        "        # Try loading as CSV first\n",
        "        if 'city_day.csv' in files:\n",
        "            df = pd.read_csv(data_path + 'city_day.csv')\n",
        "            print(f\"‚úÖ Loaded city_day.csv successfully!\")\n",
        "        elif 'city_day' in files:\n",
        "            # If it's an Excel file without extension\n",
        "            df = pd.read_excel(data_path + 'city_day')\n",
        "            print(f\"‚úÖ Loaded city_day Excel file successfully!\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è city_day file not found, checking other available files...\")\n",
        "            # Try the first available file as fallback\n",
        "            available_files = [f for f in files if f.endswith(('.csv', '.xlsx', '.xls')) or '.' not in f]\n",
        "            if available_files:\n",
        "                first_file = available_files[0]\n",
        "                if first_file.endswith('.csv'):\n",
        "                    df = pd.read_csv(data_path + first_file)\n",
        "                else:\n",
        "                    df = pd.read_excel(data_path + first_file)\n",
        "                print(f\"‚úÖ Loaded {first_file} as fallback\")\n",
        "            else:\n",
        "                print(\"‚ùå No suitable data files found\")\n",
        "                df = pd.DataFrame()\n",
        "        \n",
        "        print(f\"Dataset shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading dataset: {e}\")\n",
        "        df = pd.DataFrame()\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ùå Data directory not found: {data_path}\")\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "# Target cities for analysis\n",
        "target_cities = ['Delhi', 'Bangalore', 'Kolkata', 'Hyderabad', 'Chennai', 'Visakhapatnam']\n",
        "print(f\"\\nTarget cities for analysis: {target_cities}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä DATASET OVERVIEW\n",
            "==================================================\n",
            "Dataset Shape: (29531, 16)\n",
            "Number of Rows: 29,531\n",
            "Number of Columns: 16\n",
            "\n",
            "üìã First 5 rows:\n",
            "        City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO    SO2  \\\n",
            "0  Ahmedabad  2015-01-01    NaN   NaN   0.92  18.22  17.15  NaN   0.92  27.64   \n",
            "1  Ahmedabad  2015-01-02    NaN   NaN   0.97  15.69  16.46  NaN   0.97  24.55   \n",
            "2  Ahmedabad  2015-01-03    NaN   NaN  17.40  19.30  29.70  NaN  17.40  29.07   \n",
            "3  Ahmedabad  2015-01-04    NaN   NaN   1.70  18.48  17.97  NaN   1.70  18.59   \n",
            "4  Ahmedabad  2015-01-05    NaN   NaN  22.10  21.42  37.76  NaN  22.10  39.33   \n",
            "\n",
            "       O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n",
            "0  133.36     0.00     0.02    0.00  NaN        NaN  \n",
            "1   34.06     3.68     5.50    3.77  NaN        NaN  \n",
            "2   30.70     6.80    16.40    2.25  NaN        NaN  \n",
            "3   36.08     4.43    10.14    1.00  NaN        NaN  \n",
            "4   39.31     7.01    18.89    2.78  NaN        NaN  \n",
            "\n",
            "üìù Column Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29531 entries, 0 to 29530\n",
            "Data columns (total 16 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   City        29531 non-null  object \n",
            " 1   Date        29531 non-null  object \n",
            " 2   PM2.5       24933 non-null  float64\n",
            " 3   PM10        18391 non-null  float64\n",
            " 4   NO          25949 non-null  float64\n",
            " 5   NO2         25946 non-null  float64\n",
            " 6   NOx         25346 non-null  float64\n",
            " 7   NH3         19203 non-null  float64\n",
            " 8   CO          27472 non-null  float64\n",
            " 9   SO2         25677 non-null  float64\n",
            " 10  O3          25509 non-null  float64\n",
            " 11  Benzene     23908 non-null  float64\n",
            " 12  Toluene     21490 non-null  float64\n",
            " 13  Xylene      11422 non-null  float64\n",
            " 14  AQI         24850 non-null  float64\n",
            " 15  AQI_Bucket  24850 non-null  object \n",
            "dtypes: float64(13), object(3)\n",
            "memory usage: 3.6+ MB\n",
            "None\n",
            "\n",
            "üèôÔ∏è Available Cities: 26\n",
            "Cities in dataset: ['Ahmedabad' 'Aizawl' 'Amaravati' 'Amritsar' 'Bengaluru' 'Bhopal'\n",
            " 'Brajrajnagar' 'Chandigarh' 'Chennai' 'Coimbatore']\n",
            "\n",
            "üéØ Target Cities Found: ['Delhi', 'Kolkata', 'Hyderabad', 'Chennai', 'Visakhapatnam']\n",
            "‚ö†Ô∏è Missing Target Cities: ['Bangalore']\n",
            "\n",
            "üå¨Ô∏è AQI Column Found!\n",
            "AQI Range: 13.00 to 2049.00\n",
            "Missing AQI values: 4681\n"
          ]
        }
      ],
      "source": [
        "# Display basic information about the loaded dataset\n",
        "if not df.empty:\n",
        "    print(\"üìä DATASET OVERVIEW\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Basic info\n",
        "    print(f\"Dataset Shape: {df.shape}\")\n",
        "    print(f\"Number of Rows: {df.shape[0]:,}\")\n",
        "    print(f\"Number of Columns: {df.shape[1]}\")\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(\"\\nüìã First 5 rows:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    # Display column information\n",
        "    print(\"\\nüìù Column Information:\")\n",
        "    print(df.info())\n",
        "    \n",
        "    # Check for target cities\n",
        "    if 'City' in df.columns:\n",
        "        available_cities = df['City'].unique()\n",
        "        print(f\"\\nüèôÔ∏è Available Cities: {len(available_cities)}\")\n",
        "        print(\"Cities in dataset:\", available_cities[:10])  # Show first 10 cities\n",
        "        \n",
        "        # Check if our target cities are available\n",
        "        target_cities_found = [city for city in target_cities if city in available_cities]\n",
        "        print(f\"\\nüéØ Target Cities Found: {target_cities_found}\")\n",
        "        \n",
        "        if len(target_cities_found) < len(target_cities):\n",
        "            missing_cities = [city for city in target_cities if city not in available_cities]\n",
        "            print(f\"‚ö†Ô∏è Missing Target Cities: {missing_cities}\")\n",
        "    \n",
        "    # Check for AQI column\n",
        "    if 'AQI' in df.columns:\n",
        "        print(f\"\\nüå¨Ô∏è AQI Column Found!\")\n",
        "        print(f\"AQI Range: {df['AQI'].min():.2f} to {df['AQI'].max():.2f}\")\n",
        "        print(f\"Missing AQI values: {df['AQI'].isnull().sum()}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è AQI column not found. Available columns: {list(df.columns)}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå No data loaded. Please check the file paths and formats.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data quality assessment function defined\n",
            "Will be executed once actual dataset is loaded\n",
            "\n",
            "Example output structure:\n",
            "{'shape': (100000, 14), 'columns': ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'AQI', 'Date', 'City'], 'missing_values': {'PM2.5': 1500, 'PM10': 1200, 'AQI': 0, 'City': 0}, 'duplicate_rows': 50}\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement data quality assessment\n",
        "# This section will be completed once the actual dataset is loaded\n",
        "\n",
        "def assess_data_quality(df):\n",
        "    \"\"\"\n",
        "    Comprehensive data quality assessment function.\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): Input dataset\n",
        "        \n",
        "    Returns:\n",
        "        dict: Data quality metrics\n",
        "    \"\"\"\n",
        "    quality_metrics = {\n",
        "        'shape': df.shape,\n",
        "        'columns': list(df.columns),\n",
        "        'data_types': df.dtypes.to_dict(),\n",
        "        'missing_values': df.isnull().sum().to_dict(),\n",
        "        'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),\n",
        "        'duplicate_rows': df.duplicated().sum(),\n",
        "        'memory_usage': df.memory_usage(deep=True).sum()\n",
        "    }\n",
        "    \n",
        "    return quality_metrics\n",
        "\n",
        "# Placeholder for actual data loading\n",
        "print(\"Data quality assessment function defined\")\n",
        "print(\"Will be executed once actual dataset is loaded\")\n",
        "\n",
        "# Example of what the output will look like:\n",
        "print(\"\\nExample output structure:\")\n",
        "example_metrics = {\n",
        "    'shape': (100000, 14),\n",
        "    'columns': ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'AQI', 'Date', 'City'],\n",
        "    'missing_values': {'PM2.5': 1500, 'PM10': 1200, 'AQI': 0, 'City': 0},\n",
        "    'duplicate_rows': 50\n",
        "}\n",
        "print(example_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PredictiveAnalysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
