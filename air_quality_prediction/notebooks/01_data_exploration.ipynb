{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Data Exploration\n",
    "\n",
    "This notebook provides comprehensive exploratory data analysis (EDA) for the air quality prediction project.\n",
    "\n",
    "## Objectives\n",
    "1. Load and examine the raw air quality dataset\n",
    "2. Analyze data quality and completeness\n",
    "3. Explore city-wise patterns and distributions\n",
    "4. Identify key insights for feature engineering\n",
    "5. Generate initial visualizations\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: Kaggle \"Air Quality Data in India (2015â€“2020)\"\n",
    "- **Target Cities**: Delhi, Bangalore, Kolkata, Hyderabad, Chennai, Visakhapatnam\n",
    "- **Features**: PM2.5, PM10, NO, NO2, NOx, NH3, CO, SO2, O3, Benzene, Toluene, AQI, Date, City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed\n",
      "numpy is already installed\n",
      "matplotlib is already installed\n",
      "seaborn is already installed\n",
      "plotly is already installed\n",
      "Installing scikit-learn...\n",
      "lightgbm is already installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NANS\\anaconda3\\envs\\PredictiveAnalysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna is already installed\n",
      "Installing imbalanced-learn...\n",
      "tqdm is already installed\n",
      "joblib is already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package using pip if not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "required_packages = [\n",
    "    \"pandas\",\n",
    "    \"numpy\", \n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"plotly\",\n",
    "    \"scikit-learn\",\n",
    "    \"lightgbm\",\n",
    "    \"optuna\",\n",
    "    \"imbalanced-learn\",\n",
    "    \"tqdm\",\n",
    "    \"joblib\"\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Libraries imported successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: aqi.csv\n",
      "Dataset shape: (235785, 9)\n",
      "Columns: ['date', 'state', 'area', 'number_of_monitoring_stations', 'prominent_pollutants', 'aqi_value', 'air_quality_status', 'unit', 'note']\n"
     ]
    }
   ],
   "source": [
    "# Load the new India AQI 2023-2025 dataset\n",
    "data_path = \"../data/raw/\"\n",
    "\n",
    "# Load the uploaded AQI dataset\n",
    "df = pd.read_csv(data_path + 'aqi.csv')\n",
    "\n",
    "print(f\"Successfully loaded: aqi.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Target cities for analysis (updated for new dataset)\n",
    "# Note: The new dataset uses 'area' instead of 'city' and includes state information\n",
    "target_cities = ['Delhi', 'Mumbai', 'Bangalore', 'Kolkata', 'Hyderabad', 'Chennai']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INDIA AQI DATASET 2023-2025 ANALYSIS\n",
      "============================================================\n",
      "Dataset shape: (235785, 9)\n",
      "Columns: ['date', 'state', 'area', 'number_of_monitoring_stations', 'prominent_pollutants', 'aqi_value', 'air_quality_status', 'unit', 'note']\n",
      "\n",
      "First 5 rows:\n",
      "         date           state      area  number_of_monitoring_stations  \\\n",
      "0  30-04-2025     Maharashtra  Amravati                              2   \n",
      "1  30-04-2025           Bihar    Purnia                              1   \n",
      "2  30-04-2025  Madhya Pradesh     Katni                              1   \n",
      "3  30-04-2025    Chhattisgarh   Tumidih                              1   \n",
      "4  30-04-2025           Assam  Byrnihat                              1   \n",
      "\n",
      "  prominent_pollutants  aqi_value air_quality_status  \\\n",
      "0                 PM10         78       Satisfactory   \n",
      "1                   CO         56       Satisfactory   \n",
      "2                   O3         98       Satisfactory   \n",
      "3                 PM10        103           Moderate   \n",
      "4                PM2.5         61       Satisfactory   \n",
      "\n",
      "                                                                     unit  \\\n",
      "0  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "1  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "2  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "3  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "4  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "\n",
      "   note  \n",
      "0   NaN  \n",
      "1   NaN  \n",
      "2   NaN  \n",
      "3   NaN  \n",
      "4   NaN  \n",
      "\n",
      "Target cities found: ['Delhi', 'Mumbai', 'Kolkata', 'Hyderabad', 'Chennai']\n",
      "Total areas in dataset: 291\n",
      "Sample areas: ['Amravati', 'Purnia', 'Katni', 'Tumidih', 'Byrnihat', 'Imphal', 'Kollam', 'Barrackpore', 'Nayagarh', 'Nalbari']\n",
      "\n",
      "Total states: 32\n",
      "States: ['Maharashtra', 'Bihar', 'Madhya Pradesh', 'Chhattisgarh', 'Assam', 'Manipur', 'Kerala', 'West Bengal', 'Odisha', 'Karnataka', 'Gujarat', 'Uttarakhand', 'Tamil Nadu', 'Andhra Pradesh', 'Rajasthan', 'Uttar Pradesh', 'Punjab', 'Mizoram', 'Chandigarh', 'Telangana', 'Puducherry', 'Meghalaya', 'Himachal Pradesh', 'Jharkhand', 'Haryana', 'Arunachal Pradesh', 'Nagaland', 'Tripura', 'Delhi', 'Andaman and Nicobar Islands', 'Sikkim', 'Jammu and Kashmir']\n",
      "\n",
      "Date range: 2022-04-01 00:00:00 to 2025-04-30 00:00:00\n",
      "Duration: 1125 days\n",
      "\n",
      "AQI Statistics:\n",
      "  Range: 3.00 to 500.00\n",
      "  Mean: 111.13\n",
      "  Median: 92.00\n",
      "  Missing AQI values: 0\n",
      "\n",
      "Prominent Pollutants Distribution:\n",
      "prominent_pollutants\n",
      "PM10          111053\n",
      "PM2.5          59670\n",
      "O3             16202\n",
      "PM2.5,PM10     13199\n",
      "CO             12867\n",
      "PM10,O3         3914\n",
      "SO2             3815\n",
      "NO2             3012\n",
      "PM10,CO         2658\n",
      "PM2.5,O3        2088\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Air Quality Status Distribution:\n",
      "air_quality_status\n",
      "Satisfactory    88897\n",
      "Moderate        77537\n",
      "Good            41971\n",
      "Poor            21154\n",
      "Very Poor        5671\n",
      "Severe            555\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "int64             2\n",
      "datetime64[ns]    1\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "note    235785\n",
      "dtype: int64\n",
      "\n",
      "Policy Relevance Analysis:\n",
      "  Dataset structure: State-level AQI data with prominent pollutants\n",
      "  Policy-controllable pollutants: PM2.5, PM10, NO2, SO2, CO, O3\n",
      "  Note: This dataset provides AQI values and prominent pollutants per area\n",
      "  For ACO implementation, we'll need to restructure this data\n"
     ]
    }
   ],
   "source": [
    "# NEW DATASET ANALYSIS - India AQI 2023-2025\n",
    "print(\"=\" * 60)\n",
    "print(\"INDIA AQI DATASET 2023-2025 ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for target cities/areas\n",
    "if 'area' in df.columns:\n",
    "    available_areas = df['area'].unique()\n",
    "    target_cities_found = [city for city in target_cities if city in available_areas]\n",
    "    print(f\"\\nTarget cities found: {target_cities_found}\")\n",
    "    print(f\"Total areas in dataset: {len(available_areas)}\")\n",
    "    print(f\"Sample areas: {list(available_areas[:10])}\")\n",
    "\n",
    "# Check states\n",
    "if 'state' in df.columns:\n",
    "    available_states = df['state'].unique()\n",
    "    print(f\"\\nTotal states: {len(available_states)}\")\n",
    "    print(f\"States: {list(available_states)}\")\n",
    "\n",
    "# Check date range\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "    print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"Duration: {(df['date'].max() - df['date'].min()).days} days\")\n",
    "\n",
    "# Check for AQI column\n",
    "if 'aqi_value' in df.columns:\n",
    "    print(f\"\\nAQI Statistics:\")\n",
    "    print(f\"  Range: {df['aqi_value'].min():.2f} to {df['aqi_value'].max():.2f}\")\n",
    "    print(f\"  Mean: {df['aqi_value'].mean():.2f}\")\n",
    "    print(f\"  Median: {df['aqi_value'].median():.2f}\")\n",
    "    print(f\"  Missing AQI values: {df['aqi_value'].isnull().sum()}\")\n",
    "\n",
    "# Check prominent pollutants\n",
    "if 'prominent_pollutants' in df.columns:\n",
    "    pollutants = df['prominent_pollutants'].value_counts()\n",
    "    print(f\"\\nProminent Pollutants Distribution:\")\n",
    "    print(pollutants.head(10))\n",
    "\n",
    "# Check air quality status\n",
    "if 'air_quality_status' in df.columns:\n",
    "    status_dist = df['air_quality_status'].value_counts()\n",
    "    print(f\"\\nAir Quality Status Distribution:\")\n",
    "    print(status_dist)\n",
    "\n",
    "# Data types and missing values\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(f\"\\nMissing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Policy relevance analysis\n",
    "print(f\"\\nPolicy Relevance Analysis:\")\n",
    "print(f\"  Dataset structure: State-level AQI data with prominent pollutants\")\n",
    "print(f\"  Policy-controllable pollutants: PM2.5, PM10, NO2, SO2, CO, O3\")\n",
    "print(f\"  Note: This dataset provides AQI values and prominent pollutants per area\")\n",
    "print(f\"  For ACO implementation, we'll need to restructure this data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA TRANSFORMATION FOR ACO FEATURE SELECTION\n",
      "============================================================\n",
      "Transforming dataset for ACO implementation...\n",
      "Transformed dataset shape: (0, 57)\n",
      "Transformed dataset columns: ['date', 'state', 'area', 'number_of_monitoring_stations', 'prominent_pollutants', 'aqi_value', 'air_quality_status', 'unit', 'note', 'PM2.5_concentration', 'PM10_concentration', 'NO2_concentration', 'SO2_concentration', 'CO_concentration', 'O3_concentration', 'year', 'month', 'day', 'day_of_week', 'day_of_year', 'season', 'temperature', 'humidity', 'wind_speed', 'pressure', 'PM2.5_lag1', 'PM2.5_lag2', 'PM2.5_lag3', 'PM10_lag1', 'PM10_lag2', 'PM10_lag3', 'NO2_lag1', 'NO2_lag2', 'NO2_lag3', 'SO2_lag1', 'SO2_lag2', 'SO2_lag3', 'CO_lag1', 'CO_lag2', 'CO_lag3', 'O3_lag1', 'O3_lag2', 'O3_lag3', 'PM2.5_avg3', 'PM2.5_avg7', 'PM10_avg3', 'PM10_avg7', 'NO2_avg3', 'NO2_avg7', 'SO2_avg3', 'SO2_avg7', 'CO_avg3', 'CO_avg7', 'O3_avg3', 'O3_avg7', 'PM_ratio', 'NOx_ratio']\n",
      "\n",
      "Sample of transformed data:\n",
      "Empty DataFrame\n",
      "Columns: [area, date, aqi_value, PM2.5_concentration, PM10_concentration, temperature, humidity]\n",
      "Index: []\n",
      "\n",
      "Feature Categories:\n",
      "  Policy-controllable features: 36\n",
      "  Weather features: 4\n",
      "  Temporal features: 6\n",
      "  Total features: 57\n",
      "\n",
      "Transformed data saved to: ../data/processed/aqi_transformed_for_aco.csv\n"
     ]
    }
   ],
   "source": [
    "# DATA TRANSFORMATION FOR ACO IMPLEMENTATION\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA TRANSFORMATION FOR ACO FEATURE SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def transform_aqi_data_for_aco(df, target_cities=None):\n",
    "    \"\"\"\n",
    "    Transform the AQI dataset into a format suitable for ACO feature selection\n",
    "    \n",
    "    Args:\n",
    "        df: Original AQI dataset\n",
    "        target_cities: List of target cities to focus on\n",
    "        \n",
    "    Returns:\n",
    "        Transformed dataframe with features suitable for ACO\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy for transformation\n",
    "    df_transformed = df.copy()\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df_transformed['date'] = pd.to_datetime(df_transformed['date'], format='%d-%m-%Y')\n",
    "    \n",
    "    # Filter for target cities if specified\n",
    "    if target_cities:\n",
    "        df_transformed = df_transformed[df_transformed['area'].isin(target_cities)]\n",
    "    \n",
    "    # Create pollutant features based on prominent_pollutants\n",
    "    # This is a simplified approach - in reality, we'd need actual pollutant concentrations\n",
    "    pollutant_features = ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3']\n",
    "    \n",
    "    # Create dummy pollutant concentrations based on AQI and prominent pollutant\n",
    "    for pollutant in pollutant_features:\n",
    "        # Create a feature that represents the concentration of this pollutant\n",
    "        # This is a simplified approach - in practice, we'd need actual concentration data\n",
    "        df_transformed[f'{pollutant}_concentration'] = 0.0\n",
    "        \n",
    "        # Set concentration based on prominent pollutant and AQI\n",
    "        mask = df_transformed['prominent_pollutants'] == pollutant\n",
    "        df_transformed.loc[mask, f'{pollutant}_concentration'] = df_transformed.loc[mask, 'aqi_value']\n",
    "        \n",
    "        # For other pollutants, use a fraction of AQI (simplified approach)\n",
    "        other_mask = df_transformed['prominent_pollutants'] != pollutant\n",
    "        df_transformed.loc[other_mask, f'{pollutant}_concentration'] = df_transformed.loc[other_mask, 'aqi_value'] * 0.3\n",
    "    \n",
    "    # Create temporal features\n",
    "    df_transformed['year'] = df_transformed['date'].dt.year\n",
    "    df_transformed['month'] = df_transformed['date'].dt.month\n",
    "    df_transformed['day'] = df_transformed['date'].dt.day\n",
    "    df_transformed['day_of_week'] = df_transformed['date'].dt.dayofweek\n",
    "    df_transformed['day_of_year'] = df_transformed['date'].dt.dayofyear\n",
    "    \n",
    "    # Create season feature\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Autumn'\n",
    "    \n",
    "    df_transformed['season'] = df_transformed['month'].apply(get_season)\n",
    "    \n",
    "    # Create weather features (simulated - in practice, we'd need actual weather data)\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    df_transformed['temperature'] = np.random.normal(25, 5, len(df_transformed))\n",
    "    df_transformed['humidity'] = np.random.normal(65, 15, len(df_transformed))\n",
    "    df_transformed['wind_speed'] = np.random.normal(10, 3, len(df_transformed))\n",
    "    df_transformed['pressure'] = np.random.normal(1013, 10, len(df_transformed))\n",
    "    \n",
    "    # Create lag features (simplified)\n",
    "    df_transformed = df_transformed.sort_values(['area', 'date'])\n",
    "    for pollutant in pollutant_features:\n",
    "        df_transformed[f'{pollutant}_lag1'] = df_transformed.groupby('area')[f'{pollutant}_concentration'].shift(1)\n",
    "        df_transformed[f'{pollutant}_lag2'] = df_transformed.groupby('area')[f'{pollutant}_concentration'].shift(2)\n",
    "        df_transformed[f'{pollutant}_lag3'] = df_transformed.groupby('area')[f'{pollutant}_concentration'].shift(3)\n",
    "    \n",
    "    # Create rolling averages\n",
    "    for pollutant in pollutant_features:\n",
    "        df_transformed[f'{pollutant}_avg3'] = df_transformed.groupby('area')[f'{pollutant}_concentration'].rolling(3).mean().reset_index(0, drop=True)\n",
    "        df_transformed[f'{pollutant}_avg7'] = df_transformed.groupby('area')[f'{pollutant}_concentration'].rolling(7).mean().reset_index(0, drop=True)\n",
    "    \n",
    "    # Create interaction features\n",
    "    df_transformed['PM_ratio'] = df_transformed['PM2.5_concentration'] / (df_transformed['PM10_concentration'] + 1e-6)\n",
    "    df_transformed['NOx_ratio'] = df_transformed['NO2_concentration'] / (df_transformed['CO_concentration'] + 1e-6)\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    df_transformed = df_transformed.dropna()\n",
    "    \n",
    "    return df_transformed\n",
    "\n",
    "# Transform the data\n",
    "print(\"Transforming dataset for ACO implementation...\")\n",
    "df_aco = transform_aqi_data_for_aco(df, target_cities)\n",
    "\n",
    "print(f\"Transformed dataset shape: {df_aco.shape}\")\n",
    "print(f\"Transformed dataset columns: {list(df_aco.columns)}\")\n",
    "\n",
    "# Display sample of transformed data\n",
    "print(\"\\nSample of transformed data:\")\n",
    "print(df_aco[['area', 'date', 'aqi_value', 'PM2.5_concentration', 'PM10_concentration', 'temperature', 'humidity']].head())\n",
    "\n",
    "# Check feature categories\n",
    "policy_controllable = [col for col in df_aco.columns if any(pollutant in col for pollutant in ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3'])]\n",
    "weather_features = [col for col in df_aco.columns if col in ['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "temporal_features = [col for col in df_aco.columns if col in ['year', 'month', 'day', 'day_of_week', 'day_of_year', 'season']]\n",
    "\n",
    "print(f\"\\nFeature Categories:\")\n",
    "print(f\"  Policy-controllable features: {len(policy_controllable)}\")\n",
    "print(f\"  Weather features: {len(weather_features)}\")\n",
    "print(f\"  Temporal features: {len(temporal_features)}\")\n",
    "print(f\"  Total features: {len(df_aco.columns)}\")\n",
    "\n",
    "# Save transformed data\n",
    "df_aco.to_csv('../data/processed/aqi_transformed_for_aco.csv', index=False)\n",
    "print(f\"\\nTransformed data saved to: ../data/processed/aqi_transformed_for_aco.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DATASET OVERVIEW\n",
      "==================================================\n",
      "Dataset Shape: (235785, 9)\n",
      "Number of Rows: 235,785\n",
      "Number of Columns: 9\n",
      "\n",
      " First 5 rows:\n",
      "        date           state      area  number_of_monitoring_stations  \\\n",
      "0 2025-04-30     Maharashtra  Amravati                              2   \n",
      "1 2025-04-30           Bihar    Purnia                              1   \n",
      "2 2025-04-30  Madhya Pradesh     Katni                              1   \n",
      "3 2025-04-30    Chhattisgarh   Tumidih                              1   \n",
      "4 2025-04-30           Assam  Byrnihat                              1   \n",
      "\n",
      "  prominent_pollutants  aqi_value air_quality_status  \\\n",
      "0                 PM10         78       Satisfactory   \n",
      "1                   CO         56       Satisfactory   \n",
      "2                   O3         98       Satisfactory   \n",
      "3                 PM10        103           Moderate   \n",
      "4                PM2.5         61       Satisfactory   \n",
      "\n",
      "                                                                     unit  \\\n",
      "0  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "1  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "2  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "3  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "4  number_of_monitoring_stations in Absolute Number, aqi_value in Indices   \n",
      "\n",
      "   note  \n",
      "0   NaN  \n",
      "1   NaN  \n",
      "2   NaN  \n",
      "3   NaN  \n",
      "4   NaN  \n",
      "\n",
      " Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 235785 entries, 0 to 235784\n",
      "Data columns (total 9 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   date                           235785 non-null  datetime64[ns]\n",
      " 1   state                          235785 non-null  object        \n",
      " 2   area                           235785 non-null  object        \n",
      " 3   number_of_monitoring_stations  235785 non-null  int64         \n",
      " 4   prominent_pollutants           235785 non-null  object        \n",
      " 5   aqi_value                      235785 non-null  int64         \n",
      " 6   air_quality_status             235785 non-null  object        \n",
      " 7   unit                           235785 non-null  object        \n",
      " 8   note                           0 non-null       float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(5)\n",
      "memory usage: 16.2+ MB\n",
      "None\n",
      "\n",
      " AQI column not found. Available columns: ['date', 'state', 'area', 'number_of_monitoring_stations', 'prominent_pollutants', 'aqi_value', 'air_quality_status', 'unit', 'note']\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the loaded dataset\n",
    "if not df.empty:\n",
    "    print(\" DATASET OVERVIEW\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    print(f\"Number of Rows: {df.shape[0]:,}\")\n",
    "    print(f\"Number of Columns: {df.shape[1]}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\n First 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Display column information\n",
    "    print(\"\\n Column Information:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Check for target cities\n",
    "    if 'City' in df.columns:\n",
    "        available_cities = df['City'].unique()\n",
    "        print(f\"\\n Available Cities: {len(available_cities)}\")\n",
    "        print(\"Cities in dataset:\", available_cities[:10])  # Show first 10 cities\n",
    "        \n",
    "        # Check if our target cities are available\n",
    "        target_cities_found = [city for city in target_cities if city in available_cities]\n",
    "        print(f\"\\n Target Cities Found: {target_cities_found}\")\n",
    "        \n",
    "        if len(target_cities_found) < len(target_cities):\n",
    "            missing_cities = [city for city in target_cities if city not in available_cities]\n",
    "            print(f\" Missing Target Cities: {missing_cities}\")\n",
    "    \n",
    "    # Check for AQI column\n",
    "    if 'AQI' in df.columns:\n",
    "        print(f\"\\n AQI Column Found!\")\n",
    "        print(f\"AQI Range: {df['AQI'].min():.2f} to {df['AQI'].max():.2f}\")\n",
    "        print(f\"Missing AQI values: {df['AQI'].isnull().sum()}\")\n",
    "    else:\n",
    "        print(f\"\\n AQI column not found. Available columns: {list(df.columns)}\")\n",
    "        \n",
    "else:\n",
    "    print(\" No data loaded. Please check the file paths and formats.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality assessment function defined\n",
      "Will be executed once actual dataset is loaded\n",
      "\n",
      "Example output structure:\n",
      "{'shape': (100000, 14), 'columns': ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'AQI', 'Date', 'City'], 'missing_values': {'PM2.5': 1500, 'PM10': 1200, 'AQI': 0, 'City': 0}, 'duplicate_rows': 50}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement data quality assessment\n",
    "# This section will be completed once the actual dataset is loaded\n",
    "\n",
    "def assess_data_quality(df):\n",
    "    \"\"\"\n",
    "    Comprehensive data quality assessment function.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset\n",
    "        \n",
    "    Returns:\n",
    "        dict: Data quality metrics\n",
    "    \"\"\"\n",
    "    quality_metrics = {\n",
    "        'shape': df.shape,\n",
    "        'columns': list(df.columns),\n",
    "        'data_types': df.dtypes.to_dict(),\n",
    "        'missing_values': df.isnull().sum().to_dict(),\n",
    "        'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),\n",
    "        'duplicate_rows': df.duplicated().sum(),\n",
    "        'memory_usage': df.memory_usage(deep=True).sum()\n",
    "    }\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "# Placeholder for actual data loading\n",
    "print(\"Data quality assessment function defined\")\n",
    "print(\"Will be executed once actual dataset is loaded\")\n",
    "\n",
    "# Example of what the output will look like:\n",
    "print(\"\\nExample output structure:\")\n",
    "example_metrics = {\n",
    "    'shape': (100000, 14),\n",
    "    'columns': ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'AQI', 'Date', 'City'],\n",
    "    'missing_values': {'PM2.5': 1500, 'PM10': 1200, 'AQI': 0, 'City': 0},\n",
    "    'duplicate_rows': 50\n",
    "}\n",
    "print(example_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PredictiveAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
